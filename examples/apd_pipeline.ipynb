{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "The following subjects did not complete the speech exposure phase and were removed:\n",
    "- 57\n",
    "- 93\n",
    "- 16\n",
    "- 87\n",
    "- 8\n",
    "- 21\n",
    "- 88\n",
    "- 84\n",
    "- 23\n",
    "\n",
    "The following subjects did not complete the bug exposure task and were removed: \n",
    "- 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example implementation of the AffectEval pipeline using the APD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"../affecteval\"))\n",
    "sys.path.insert(0, module_path)\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "sys.path.insert(0, module_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import apd\n",
    "\n",
    "from affecteval import signals\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "ROOT_DIR = \"/Users/emilyzhou/Desktop/Research/CAREForMe/\"\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "APD_PATH = os.path.join(DATA_DIR, \"APD\")\n",
    "SOURCE_FOLDER = os.path.join(APD_PATH, \"formatted\")\n",
    "METRICS = os.path.join(DATA_DIR, \"metrics\", \"APD\")\n",
    "\n",
    "ALL = \"all\"\n",
    "HA = \"high_anxiety_group\"\n",
    "LA = \"low_anxiety_group\"\n",
    "\n",
    "ha_participant_indices = [\n",
    "    '4', '6', '7', '8', '10', '12', '15', '16', '18', '22', '26', '27', '29', '31', '32', '33', '35', '42', '45', '47', '48', '49', '54', '55', '66', '69'\n",
    "]\n",
    "\n",
    "la_participant_indices = [\n",
    "    '14', '21', '23', '25', '34', '39', '43', '46', '51', '57', '71', '72', '77', '78', '79', '80', '82', '83', '84', '85', '87', '88', '89', '91', '92', '93'\n",
    "]\n",
    "\n",
    "SUBJECTS = ha_participant_indices.extend(la_participant_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data to be compatible with CAREforMe pipeline\n",
    "# Only needs to be run once locally\n",
    "# Status: COMPLETE, do not re-run\n",
    "apd.reformat_and_save_data(APD_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = apd.get_suds_labels(APD_PATH)\n",
    "# print(labels)\n",
    "\n",
    "def generate_labels(data):\n",
    "    \"\"\"\n",
    "    Generate binary labels for APD based on the SUDS questionnaire and the input data format.\n",
    "    \n",
    "    Parameters\n",
    "    --------------------\n",
    "    :param data: Features to generate labels for. Must include subject ID and phase columns.\n",
    "    :type data: pd.DataFrame\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "    Generated labels and the unmodified input data.\n",
    "    \"\"\"\n",
    "    print(data.shape)\n",
    "    annotations = apd.get_suds_labels(APD_PATH)\n",
    "    labels = []\n",
    "    for i in range(data.shape[0]):\n",
    "        subject = int(data[\"subject\"].iloc[i])\n",
    "        phase = data[\"Phase\"].iloc[i]\n",
    "        label_row = annotations.loc[(annotations[\"subject\"] == subject)]\n",
    "        label = label_row[phase]\n",
    "        labels.append(label)\n",
    "    labels = np.array(labels).ravel()\n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary stress classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running node Signal Acquisition...\n",
      "- Elapsed time: 0.0 s\n",
      "Running node Signal Preprocessor...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m aucs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# We leave it up to the user to handle the final output of the pipeline. \u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# Results\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m# fitted_model = out[0]\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/Research/CAREForMe/care_for_me/pipeline/pipeline.py:38\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 38\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Elapsed time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(end\u001b[38;5;241m-\u001b[39mstart,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Research/CAREForMe/care_for_me/pipeline/node.py:14\u001b[0m, in \u001b[0;36mNode.run\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_inputs(data):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Research/CAREForMe/care_for_me/signal_preprocessor/signal_preprocessor.py:131\u001b[0m, in \u001b[0;36mSignalPreprocessor.run\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;66;03m# Add updated timestamp column\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# TODO: Fix timestamp generation. This sets the timestamp of the first sample to 0, which isn't necessarily what we want. \u001b[39;00m\n\u001b[1;32m    130\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39msampling_rate\u001b[38;5;241m*\u001b[39mj \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(temp\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]    \n\u001b[0;32m--> 131\u001b[0m \u001b[43mtemp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m temp\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhase\u001b[39m\u001b[38;5;124m\"\u001b[39m, phase)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_processed_data[subject]\u001b[38;5;241m.\u001b[39mappend(temp)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/frame.py:5156\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m allow_duplicates \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mallows_duplicate_labels:\n\u001b[1;32m   5152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5153\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot specify \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mallow_duplicates=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5154\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself.flags.allows_duplicate_labels\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5155\u001b[0m     )\n\u001b[0;32m-> 5156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_duplicates \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m:\n\u001b[1;32m   5157\u001b[0m     \u001b[38;5;66;03m# Should this be a different kind of error??\u001b[39;00m\n\u001b[1;32m   5158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot insert \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(loc):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:5360\u001b[0m, in \u001b[0;36mIndex.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5358\u001b[0m \u001b[38;5;28mhash\u001b[39m(key)\n\u001b[1;32m   5359\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\n\u001b[1;32m   5361\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOverflowError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   5362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:847\u001b[0m, in \u001b[0;36mIndex._engine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_engine\u001b[39m(\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    845\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m libindex\u001b[38;5;241m.\u001b[39mIndexEngine \u001b[38;5;241m|\u001b[39m libindex\u001b[38;5;241m.\u001b[39mExtensionEngine \u001b[38;5;241m|\u001b[39m libindex\u001b[38;5;241m.\u001b[39mMaskedIndexEngine:\n\u001b[1;32m    846\u001b[0m     \u001b[38;5;66;03m# For base class (object dtype) we get ObjectEngine\u001b[39;00m\n\u001b[0;32m--> 847\u001b[0m     target_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_engine_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values, ArrowExtensionArray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    850\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:5176\u001b[0m, in \u001b[0;36mIndex._get_engine_target\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5172\u001b[0m \u001b[38;5;124;03mGet the ndarray or ExtensionArray that we can pass to the IndexEngine\u001b[39;00m\n\u001b[1;32m   5173\u001b[0m \u001b[38;5;124;03mconstructor.\u001b[39;00m\n\u001b[1;32m   5174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5175\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 5176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStringArray\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   5177\u001b[0m     \u001b[38;5;66;03m# GH#45652 much more performant than ExtensionEngine\u001b[39;00m\n\u001b[1;32m   5178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vals\u001b[38;5;241m.\u001b[39m_ndarray\n\u001b[1;32m   5179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(vals, ArrowExtensionArray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMm\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m<frozen abc>:117\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build pipeline with default preprocessing and feature extraction methods\n",
    "\n",
    "from affecteval.signal_acquisition.signal_acquisition import SignalAcquisition\n",
    "from affecteval.signal_preprocessor.signal_preprocessor import SignalPreprocessor\n",
    "from affecteval.feature_extractor.feature_extractor import FeatureExtractor\n",
    "from affecteval.label_generator.label_generator import LabelGenerator\n",
    "from affecteval.feature_selector.feature_selector import FeatureSelector\n",
    "from affecteval.classification.estimator import Estimator\n",
    "from affecteval.pipeline.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "signal_types = [\n",
    "    signals.Signals.ECG,\n",
    "    signals.Signals.EDA\n",
    "]\n",
    "feature_names = [\n",
    "    signals.Features.HR, signals.Features.RMSSD, signals.Features.SDNN,\n",
    "    # signals.Features.HR,\n",
    "    signals.Features.MEAN_SCL, signals.Features.SCR_RATE\n",
    "]\n",
    "\n",
    "label_gen = generate_labels\n",
    "signal_acq = SignalAcquisition(source_folder=SOURCE_FOLDER, signal_types=signal_types)\n",
    "signal_preprocessor = SignalPreprocessor(skip=True, resample_rate=100)\n",
    "feature_extractor = FeatureExtractor()\n",
    "label_generator = LabelGenerator(label_generation_method=label_gen)\n",
    "\n",
    "model = SVC()\n",
    "feature_selector = FeatureSelector(model, feature_names, num_features=3)\n",
    "estimator_train = Estimator(0, model, name=\"SVC training\")\n",
    "estimator_test = Estimator(1, model, name=\"SVC testing\")\n",
    "estimator_train_val_test = Estimator(2, model, name=\"SVC train-val-test\")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "\n",
    "pipeline.generate_nodes_from_layers(\n",
    "    # [signal_acq, signal_preprocessor, feature_extractor]\n",
    "    # [signal_acq, signal_preprocessor, feature_extractor, label_generator, feature_selector]\n",
    "    # [signal_acq, signal_preprocessor, feature_extractor, label_generator, feature_selector, estimator_train, estimator_test]\n",
    "    [signal_acq, signal_preprocessor, feature_extractor, label_generator, feature_selector, estimator_train_val_test]\n",
    ")\n",
    "\n",
    "accs = []\n",
    "aucs = []\n",
    "\n",
    "for i in range(5):\n",
    "    # We leave it up to the user to handle the final output of the pipeline. \n",
    "    out = pipeline.run()\n",
    "\n",
    "    # Results\n",
    "    # fitted_model = out[0]\n",
    "    y_true = out[1]\n",
    "    y_pred = out[2]\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred)\n",
    "    # f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    accs.append(acc)\n",
    "    aucs.append(auc)\n",
    "\n",
    "print(f\"\\nMean accuracy: {np.mean(accs)}\")\n",
    "print(f\"STD accuracy: {np.std(accs)}\")\n",
    "print(f\"Mean AUC score: {np.mean(aucs)}\")\n",
    "print(f\"STD AUC score: {np.std(aucs)}\")\n",
    "# print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running node Signal Acquisition...\n",
      "- Elapsed time: 0.0 s\n",
      "Running node Signal Preprocessor...\n",
      "- Elapsed time: 11.389 s\n",
      "Running node Feature Extractor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:14<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Elapsed time: 14.386 s\n",
      "Running node Label Generator...\n",
      "- Elapsed time: 0.0 s\n",
      "Running node Feature Selector...\n",
      "- Elapsed time: 1.567 s\n",
      "Running node SVC train-val-test...\n",
      "Cross-validation scores: [0.06666667 0.08333333 0.06666667 0.06666667 0.05      ]\n",
      "- Elapsed time: 0.055 s\n",
      "\n",
      "Accuracy: 0.039473684210526314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build pipeline with default preprocessing and feature extraction methods\n",
    "\n",
    "from affecteval.signal_acquisition.signal_acquisition import SignalAcquisition\n",
    "from affecteval.signal_preprocessor.signal_preprocessor import SignalPreprocessor\n",
    "from affecteval.feature_extractor.feature_extractor import FeatureExtractor\n",
    "from affecteval.label_generator.label_generator import LabelGenerator\n",
    "from affecteval.feature_selector.feature_selector import FeatureSelector\n",
    "from affecteval.classification.estimator import Estimator\n",
    "from affecteval.pipeline.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "signal_types = [\n",
    "    signals.Signals.ECG,\n",
    "    signals.Signals.EDA\n",
    "]\n",
    "feature_names = [\n",
    "    signals.Features.HR, signals.Features.RMSSD, signals.Features.SDNN,\n",
    "    # signals.Features.HR,\n",
    "    signals.Features.MEAN_SCL, signals.Features.SCR_RATE\n",
    "]\n",
    "\n",
    "label_gen = \"subject\"\n",
    "signal_acq = SignalAcquisition(source_folder=SOURCE_FOLDER, signal_types=signal_types)\n",
    "signal_preprocessor = SignalPreprocessor(skip=True, resample_rate=100)\n",
    "feature_extractor = FeatureExtractor()\n",
    "label_generator = LabelGenerator(label_generation_method=label_gen)\n",
    "\n",
    "model = SVC()\n",
    "feature_selector = FeatureSelector(model, feature_names, num_features=3)\n",
    "estimator_train = Estimator(0, model, name=\"SVC training\")\n",
    "estimator_test = Estimator(1, model, name=\"SVC testing\")\n",
    "estimator_train_val_test = Estimator(2, model, name=\"SVC train-val-test\")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "\n",
    "pipeline.generate_nodes_from_layers(\n",
    "    # [signal_acq, signal_preprocessor, feature_extractor]\n",
    "    # [signal_acq, signal_preprocessor, feature_extractor, label_generator, feature_selector]\n",
    "    # [signal_acq, signal_preprocessor, feature_extractor, label_generator, feature_selector, estimator_train, estimator_test]\n",
    "    [signal_acq, signal_preprocessor, feature_extractor, label_generator, feature_selector, estimator_train_val_test]\n",
    ")\n",
    "\n",
    "out = pipeline.run()\n",
    "\n",
    "# Results\n",
    "# fitted_model = out[0]\n",
    "y_true = out[1]\n",
    "y_pred = out[2]\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "# f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy: {acc}\")\n",
    "# print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running node Signal Acquisition...\n",
      "- Elapsed time: 0.0 s\n",
      "Running node Signal Preprocessor...\n",
      "- Elapsed time: 11.019 s\n",
      "Running node Feature Extractor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:14<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Elapsed time: 14.153 s\n",
      "Running node Label Generator...\n",
      "- Elapsed time: 0.001 s\n",
      "Running node Feature Selector...\n",
      "- Elapsed time: 0.246 s\n",
      "Running node SVC train-val-test...\n",
      "Cross-validation scores: [0.16666667 0.11666667 0.11666667 0.08333333 0.18333333]\n",
      "- Elapsed time: 0.03 s\n",
      "\n",
      "Accuracy: 0.10526315789473684\n"
     ]
    }
   ],
   "source": [
    "# Build pipeline with default preprocessing and feature extraction methods\n",
    "\n",
    "from affecteval.signal_acquisition.signal_acquisition import SignalAcquisition\n",
    "from affecteval.signal_preprocessor.signal_preprocessor import SignalPreprocessor\n",
    "from affecteval.feature_extractor.feature_extractor import FeatureExtractor\n",
    "from affecteval.label_generator.label_generator import LabelGenerator\n",
    "from affecteval.feature_selector.feature_selector import FeatureSelector\n",
    "from affecteval.classification.estimator import Estimator\n",
    "from affecteval.pipeline.pipeline import Pipeline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "signal_types = [\n",
    "    signals.Signals.ECG,\n",
    "    signals.Signals.EDA\n",
    "]\n",
    "feature_names = [\n",
    "    signals.Features.HR, signals.Features.RMSSD, signals.Features.SDNN,\n",
    "    # signals.Features.HR,\n",
    "    signals.Features.MEAN_SCL, signals.Features.SCR_RATE\n",
    "]\n",
    "\n",
    "label_gen = \"phase\"\n",
    "signal_acq = SignalAcquisition(source_folder=SOURCE_FOLDER, signal_types=signal_types)\n",
    "signal_preprocessor = SignalPreprocessor(skip=True, resample_rate=100)\n",
    "feature_extractor = FeatureExtractor()\n",
    "label_generator = LabelGenerator(label_generation_method=label_gen)\n",
    "\n",
    "model = SVC()\n",
    "feature_selector = FeatureSelector(model, feature_names, num_features=3)\n",
    "estimator_train = Estimator(0, model, name=\"SVC training\")\n",
    "estimator_test = Estimator(1, model, name=\"SVC testing\")\n",
    "estimator_train_val_test = Estimator(2, model, name=\"SVC train-val-test\")\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "\n",
    "pipeline.generate_nodes_from_layers(\n",
    "    # [signal_acq, signal_preprocessor, feature_extractor]\n",
    "    # [signal_acq, signal_preprocessor, feature_extractor, label_generator, feature_selector]\n",
    "    # [signal_acq, signal_preprocessor, feature_extractor, label_generator, feature_selector, estimator_train, estimator_test]\n",
    "    [signal_acq, signal_preprocessor, feature_extractor, label_generator, feature_selector, estimator_train_val_test]\n",
    ")\n",
    "\n",
    "out = pipeline.run()\n",
    "\n",
    "# Results\n",
    "# fitted_model = out[0]\n",
    "y_true = out[1]\n",
    "y_pred = out[2]\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "# f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"\\nAccuracy: {acc}\")\n",
    "# print(f\"F1-score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
