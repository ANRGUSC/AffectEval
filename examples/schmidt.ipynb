{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"../care_for_me\"))\n",
    "sys.path.insert(0, module_path)\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "sys.path.insert(0, module_path)\n",
    "\n",
    "import biosppy as bp\n",
    "import heartpy as hp\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyhrv\n",
    "import pyhrv.time_domain as td\n",
    "import scipy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from care_for_me.signals import Features, Signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"../care_for_me\"))\n",
    "sys.path.insert(0, module_path)\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "sys.path.insert(0, module_path)\n",
    "\n",
    "import wesad\n",
    "\n",
    "subject_indices = list(range(2, 12)) + list(range(13, 18))\n",
    "SUBJECTS = [str(i) for i in subject_indices]\n",
    "\n",
    "# NOTE: Change ROOT_DIR according to your own file structure. This will be the only place you will need to do this.\n",
    "ROOT_DIR = \"/Users/emilyzhou/Desktop/Research/CAREForMe/\"\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "WESAD_PATH = os.path.join(DATA_DIR, \"WESAD\")\n",
    "SOURCE_FOLDER = os.path.join(WESAD_PATH, \"formatted\")\n",
    "ANNOTATIONS_PATH = os.path.join(WESAD_PATH, \"annotations\")\n",
    "METRICS = os.path.join(DATA_DIR, \"metrics\", \"WESAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data to be compatible with CAREforMe pipeline\n",
    "# Only needs to be run once locally \n",
    "# Status: COMPLETE, do not re-run\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "wesad.reformat_and_save_data(WESAD_PATH)\n",
    "\n",
    "# Rename Medi_1 and Medi_2 files to Medi1 and Medi2\n",
    "# files_to_rename = glob.glob(os.path.join(SOURCE_FOLDER, \"*/*Medi_*.csv\"))\n",
    "# for file in files_to_rename:\n",
    "#     file_name = file.split(\"_\")\n",
    "#     new_name = f\"{file_name[0]}_{file_name[1]}{file_name[2]}_{file_name[3]}\"\n",
    "#     os.rename(file, new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate WESAD labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels_3_class(data):\n",
    "    labels = []\n",
    "    for i in range(data.shape[0]):\n",
    "        phase = data[\"Phase\"].iloc[i]\n",
    "        if phase == \"Base\":     # Baseline\n",
    "            labels.append(0)\n",
    "        elif phase == \"TSST\": \n",
    "            labels.append(1)    # Stress\n",
    "        elif phase == \"Fun\":\n",
    "            labels.append(2)    # Amusement\n",
    "    labels = np.array(labels).ravel()\n",
    "    return labels, data\n",
    "\n",
    "def generate_labels_binary(data):\n",
    "    labels = []\n",
    "    for i in range(data.shape[0]):\n",
    "        phase = data[\"Phase\"].iloc[i]\n",
    "        if phase == \"Base\" or phase == \"Fun\":     # Non-stress\n",
    "            labels.append(0)\n",
    "        elif phase == \"TSST\": \n",
    "            labels.append(1)    # Stress\n",
    "    labels = np.array(labels).ravel()\n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "# Preprocessing methods\n",
    "\n",
    "# ECG ------------------------------\n",
    "def preprocess_ecg(data, fs):\n",
    "    return data\n",
    "\n",
    "# EDA ------------------------------\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def preprocess_eda(data, fs):\n",
    "    return butter_lowpass_filter(data, 5, fs)\n",
    "\n",
    "# EMG ------------------------------\n",
    "def preprocess_emg(data, fs):\n",
    "    return data\n",
    "\n",
    "# RESP ------------------------------\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def preprocess_resp(data, fs):\n",
    "    return butter_bandpass_filter(data, 0.1, 0.35, fs)\n",
    "\n",
    "# TEMP ------------------------------\n",
    "def preprocess_temp(data, fs):\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION TEMPLATE\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical/common feature extraction methods\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_mean(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.mean(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.mean(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_med(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.median(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.median(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_std(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.std(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.std(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_var(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.var(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.var(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_range(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.max(segment) - np.min(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.max(segment) - np.min(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_peak(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.max(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.max(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_slope(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.gradient(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.gradient(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract power from frequency bands\n",
    "\n",
    "\n",
    "def bandpower(x, fs, fmin, fmax):\n",
    "    f, Pxx = scipy.signal.periodogram(x, fs=fs)\n",
    "    ind_min = scipy.argmax(f > fmin) - 1\n",
    "    ind_max = scipy.argmax(f > fmax) - 1\n",
    "    return scipy.trapz(Pxx[ind_min: ind_max], f[ind_min: ind_max])\n",
    "\n",
    "def extract_freq_power(data, fs, low, high):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = bandpower(segment, fs, low, high)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = bandpower(segment, fs, low, high)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG feature extraction methods\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_ecg_features_pyhrv(data, fs):\n",
    "    n = data.size\n",
    "    if n == 0:\n",
    "        print(\"ECG signal has length 0, returning None\")\n",
    "        return None\n",
    "    \n",
    "    hr = []\n",
    "    rmssd = []\n",
    "    sdnn = []\n",
    "\n",
    "    start = 0\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "    stop = start + window_size\n",
    "    if stop >= n:\n",
    "        t, filtered_signal, rpeaks, _, _, _, bpm = bp.signals.ecg.ecg(signal=data, sampling_rate=fs, show=False)\n",
    "        bpm = np.mean(bpm)\n",
    "        rmssd_segment = td.rmssd(rpeaks=t[rpeaks])[\"rmssd\"]\n",
    "        sdnn_segment = td.sdnn(rpeaks=t[rpeaks])[\"sdnn\"]\n",
    "\n",
    "        hr.append(bpm)\n",
    "        rmssd.append(rmssd_segment)\n",
    "        sdnn.append(sdnn_segment)\n",
    "    else:\n",
    "        while stop < n:\n",
    "            stop = start + window_size\n",
    "            segment = data[start:stop]\n",
    "            segment, info = nk.ecg_process(segment, sampling_rate=fs)\n",
    "            segment = segment[\"ECG_Clean\"]\n",
    "            t, filtered_signal, rpeaks, _, _, _, bpm = bp.signals.ecg.ecg(signal=segment, sampling_rate=fs, show=False)\n",
    "            try:\n",
    "                segment = data.iloc[start:stop]\n",
    "            except AttributeError:\n",
    "                segment = data[start:stop]\n",
    "            try:\n",
    "                bpm = np.mean(bpm)\n",
    "                rmssd_segment = td.rmssd(rpeaks=t[rpeaks])[\"rmssd\"]\n",
    "                sdnn_segment = td.sdnn(rpeaks=t[rpeaks])[\"sdnn\"]\n",
    "            except Exception as e:\n",
    "                bpm = np.nan\n",
    "                rmssd_segment = np.nan\n",
    "                sdnn_segment = np.nan\n",
    "            hr.append(bpm)\n",
    "            rmssd.append(rmssd_segment)\n",
    "            sdnn.append(sdnn_segment)\n",
    "            start = stop - overlap\n",
    "    return hr, rmssd, sdnn\n",
    "    \n",
    "def extract_hr(data, fs):\n",
    "    hr, _, _ = extract_ecg_features_pyhrv(data, fs)\n",
    "    return hr\n",
    "\n",
    "def extract_rmssd(data, fs):\n",
    "    _, rmssd, _ = extract_ecg_features_pyhrv(data, fs)\n",
    "    return rmssd\n",
    "\n",
    "def extract_sdnn(data, fs):\n",
    "    _, _, sdnn = extract_ecg_features_pyhrv(data, fs)\n",
    "    return sdnn\n",
    "\n",
    "def extract_hr_mean(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        t, filtered_signal, rpeaks, _, _, _, bpm = bp.signals.ecg.ecg(signal=data, sampling_rate=fs, show=False)\n",
    "        bpm = np.mean(bpm)\n",
    "        out.append(bpm)\n",
    "    else:\n",
    "        while stop < n:\n",
    "            stop = start + window_size\n",
    "            segment = data[start:stop]\n",
    "            segment, info = nk.ecg_process(segment, sampling_rate=fs)\n",
    "            segment = segment[\"ECG_Clean\"]\n",
    "            t, filtered_signal, rpeaks, _, _, _, bpm = bp.signals.ecg.ecg(signal=segment, sampling_rate=fs, show=False)\n",
    "            try:\n",
    "                segment = data.iloc[start:stop]\n",
    "            except AttributeError:\n",
    "                segment = data[start:stop]\n",
    "            try:\n",
    "                bpm = np.mean(bpm)\n",
    "            except Exception as e:\n",
    "                bpm = np.nan\n",
    "            out.append(bpm)\n",
    "            start = stop - overlap\n",
    "    out = [np.mean(out)]\n",
    "    return out\n",
    "\n",
    "def extract_tinn(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = pyhrv.hrv.hrv(\n",
    "            signal=segment, sampling_rate=fs, plot_ecg=False, plot_Tachogram=False, show=False\n",
    "        )[\"tinn\"]\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = pyhrv.hrv.hrv(\n",
    "            signal=segment, sampling_rate=fs, plot_ecg=False, plot_Tachogram=False, show=False\n",
    "        )[\"tinn\"]\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_nn50(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = pyhrv.hrv.hrv(\n",
    "            signal=segment, sampling_rate=fs, plot_ecg=False, plot_Tachogram=False, show=False\n",
    "        )[\"nn50\"]\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = pyhrv.hrv.hrv(\n",
    "            signal=segment, sampling_rate=fs, plot_ecg=False, plot_Tachogram=False, show=False\n",
    "        )[\"nn50\"]\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_ulf(data, fs):\n",
    "    low = 0\n",
    "    high = 0.03\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "\n",
    "def extract_lf(data, fs):\n",
    "    low = 0.03\n",
    "    high = 0.5\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "\n",
    "def extract_hf(data, fs):\n",
    "    low = 0.12\n",
    "    high = 0.488\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "\n",
    "def extract_uhf(data, fs):\n",
    "    low = 150\n",
    "    high = 250\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "\n",
    "def extract_lf_hf_ratio(data, fs):\n",
    "    lf = extract_lf\n",
    "    hf = extract_hf\n",
    "    return np.divide(lf, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA feature extraction\n",
    "\n",
    "# Minimum threshold by which to exclude SCRs (peaks) as relative to the largest amplitude in the signal (from neurokit documentation)\n",
    "MIN_AMP = 0.3 \n",
    "def extract_eda_features_nk(signal, fs):\n",
    "    signal = signal.iloc[:, -1]\n",
    "    \n",
    "    signal = signal.astype(np.double)\n",
    "    signal = hp.scale_data(signal)\n",
    "    signal = scipy.n# EMG feature extractiondimage.median_filter(signal, int(fs))  # Median smoothing to reject outliers\n",
    "    signals, info = nk.eda_process(signal, sampling_rate=fs)\n",
    "    phasic = signals[\"EDA_Phasic\"].to_numpy()\n",
    "    tonic = signals[\"EDA_Tonic\"].to_numpy()\n",
    "\n",
    "    peak_info = nk.eda_findpeaks(phasic, fs, amplitude_min=MIN_AMP)\n",
    "    peak_idx = peak_info[\"SCR_Peaks\"].astype(int)\n",
    "    peak_amps = peak_info[\"SCR_Height\"]\n",
    "    peaks = np.zeros(phasic.shape)\n",
    "    np.put(peaks, peak_idx, [1])\n",
    "    tonic = tonic - peaks\n",
    "\n",
    "    return tonic, peaks\n",
    "\n",
    "def extract_mean_scl(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    out = []\n",
    "\n",
    "    tonic, _ = extract_eda_features_nk(data)\n",
    "\n",
    "    if tonic is None:\n",
    "        print(\"mean SCL is None\")\n",
    "        return None\n",
    "    \n",
    "    n = tonic.size\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = tonic\n",
    "        segment_mean = np.mean(segment)\n",
    "        out.append(segment_mean)\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = tonic[start:stop]\n",
    "        segment_mean = np.mean(segment)\n",
    "        out.append(segment_mean)\n",
    "        start = stop - overlap\n",
    "    mean_scl = list(out)\n",
    "    return mean_scl\n",
    "\n",
    "def extract_scr_rate(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    out = []\n",
    "\n",
    "    _, peaks = extract_eda_features_nk(data)\n",
    "\n",
    "    if peaks is None:\n",
    "        print(\"SCR rate is None\")\n",
    "        return None\n",
    "\n",
    "    n = peaks.size\n",
    "    \n",
    "    if stop >= n:\n",
    "        segment = peaks\n",
    "        num_peaks = sum(segment)\n",
    "        out.append(num_peaks)\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = peaks[start:stop]\n",
    "        num_peaks = sum(segment)\n",
    "        out.append(num_peaks)\n",
    "        start = stop - overlap\n",
    "    scr_rate = list(out)\n",
    "    return scr_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMG feature extraction\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_emg_psd_1(data, fs):\n",
    "    low = 0\n",
    "    high = 50\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_2(data, fs):\n",
    "    low = 50\n",
    "    high = 100\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_3(data, fs):\n",
    "    low = 100\n",
    "    high = 150\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_4(data, fs):\n",
    "    low = 150\n",
    "    high = 200\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_5(data, fs):\n",
    "    low = 200\n",
    "    high = 250\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_6(data, fs):\n",
    "    low = 250\n",
    "    high = 300\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_7(data, fs):\n",
    "    low = 300\n",
    "    high = 350\n",
    "    return extract_freq_power(data, fs, low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESP feature extraction\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_resp(data, fs):\n",
    "    return nk.rsp_process(data, fs)\n",
    "\n",
    "def extract_resp_mean_inh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        feature = feature.value_counts().get(1, 0)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        feature = feature.value_counts().get(1, 0)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_mean_exh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        feature = feature.value_counts().get(0)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        feature = feature.value_counts().get(0)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_std_inh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_std_exh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_inh_exh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        inh = feature.value_counts().get(1, 0)\n",
    "        exh = feature.value_counts().get(0)\n",
    "        feature = inh/exh\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        inh = feature.value_counts().get(1, 0)\n",
    "        exh = feature.value_counts().get(0)\n",
    "        feature = inh/exh\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_vol(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = np.mean(segment[\"RSP_RVT\"])\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.mean(segment[\"RSP_RVT\"])\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_rate(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = np.mean(segment[\"RSP_Rate\"])\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.mean(segment[\"RSP_Rate\"])\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_duration(data, fs):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from care_for_me.signal_acquisition.signal_acquisition import SignalAcquisition\n",
    "from care_for_me.signal_preprocessor.signal_preprocessor import SignalPreprocessor\n",
    "from care_for_me.feature_extractor.feature_extractor import FeatureExtractor\n",
    "from care_for_me.label_generator.label_generator import LabelGenerator\n",
    "from care_for_me.classification.estimator import Estimator\n",
    "from care_for_me.pipeline.pipeline import Pipeline\n",
    "\n",
    "\n",
    "signal_types = [\n",
    "    Signals.ECG,\n",
    "    Signals.EDA,\n",
    "    Signals.EMG,\n",
    "    Signals.RESP,\n",
    "    Signals.TEMP,\n",
    "]\n",
    "feature_names = [\n",
    "    Features.ECG_MEAN, Features.ECG_MEDIAN, Features.ECG_STD, Features.ECG_VAR,\n",
    "    Features.HR, Features.HR_MEAN, Features.RMSSD, Features.RMSSD_MEAN, Features.SDNN, Features.NN50, Features.TINN,\n",
    "    Features.ULF, Features.LF, Features.HF, Features.UHF, Features.LF_NORM, Features.HF_NORM, Features.LF_HF,\n",
    "    Features.EDA_MEAN, Features.EDA_MEDIAN, Features.EDA_STD, Features.EDA_VAR, Features.EDA_SLOPE, Features.EDA_RANGE,\n",
    "    Features.MEAN_SCL, Features.SCR_RATE,\n",
    "    Features.EMG_MEAN, Features.EMG_MEDIAN, Features.EMG_STD, Features.EMG_VAR, Features.EMG_10, Features.EMG_90, Features.EMG_NUM_PEAKS, Features.EMG_PEAK_MEAN, Features.EMG_PEAK_STD, Features.EMG_PEAK_AMP,\n",
    "    Features.EMG_F_MEAN, Features.EMG_F_MED, Features.EMG_F_PEAK, Features.EMG_PSD_1, Features.EMG_PSD_2, Features.EMG_PSD_3, Features.EMG_PSD_4, Features.EMG_PSD_5, Features.EMG_PSD_6, Features.EMG_PSD_7,\n",
    "    Features.RESP_MEAN_INH, Features.RESP_MEAN_EXH, Features.RESP_STD_INH, Features.RESP_STD_EXH, Features.RESP_INH_EXH, Features.RESP_RANGE, Features.RESP_VOL, Features.RESP_RATE, Features.RESP_DURATION,\n",
    "    Features.TEMP_MEAN, Features.TEMP_STD, Features.TEMP_MIN, Features.TEMP_MAX, Features.TEMP_SLOPE, Features.TEMP_RANGE\n",
    "]\n",
    "\n",
    "preprocessing_methods = {\n",
    "    \"ECG\": preprocess_ecg,\n",
    "    \"EDA\": preprocess_eda,\n",
    "    \"EMG\": preprocess_emg,\n",
    "    \"RESP\": preprocess_resp,\n",
    "    \"TEMP\": preprocess_temp\n",
    "}\n",
    "\n",
    "feature_extraction_methods = {\n",
    "    \"ECG\": {\n",
    "        Features.ECG_MEAN: extract_mean,\n",
    "        Features.ECG_MEDIAN: extract_med,\n",
    "        Features.ECG_STD: extract_std,\n",
    "        Features.ECG_VAR: extract_var,\n",
    "        Features.HR: extract_hr, Features.HR_MEAN: extract_hr_mean, \n",
    "        Features.RMSSD: extract_rmssd, Features.RMSSD_MEAN: extract_rmssd, \n",
    "        Features.SDNN: extract_sdnn, Features.NN50: extract_nn50, Features.TINN: extract_tinn,\n",
    "        Features.ULF: extract_ulf, Features.LF: extract_lf, Features.HF: extract_hf, Features.UHF: extract_uhf, \n",
    "        # Features.LF_NORM: extract_lf, Features.HF_NORM: extract_hf, \n",
    "        Features.LF_HF: extract_lf_hf_ratio,\n",
    "    },\n",
    "    \"EDA\": {\n",
    "        Features.EDA_MEAN: extract_mean,\n",
    "        Features.EDA_MEDIAN: extract_med,\n",
    "        Features.EDA_STD: extract_std,\n",
    "        Features.EDA_VAR: extract_var,\n",
    "        Features.EDA_SLOPE: extract_slope,\n",
    "        Features.EDA_RANGE: extract_range,\n",
    "        Features.MEAN_SCL: extract_mean_scl, Features.SCR_RATE: extract_scr_rate,\n",
    "    },\n",
    "    \"EMG\": {\n",
    "        Features.EMG_MEAN: extract_mean,\n",
    "        Features.EMG_MEDIAN: extract_med,\n",
    "        Features.EMG_STD: extract_std,\n",
    "        Features.EMG_VAR: extract_var,\n",
    "\n",
    "    },\n",
    "    \"RESP\": {\n",
    "\n",
    "    },\n",
    "    \"TEMP\": {\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from care_for_me.signal_acquisition.signal_acquisition import SignalAcquisition\n",
    "from care_for_me.signal_preprocessor.signal_preprocessor import SignalPreprocessor\n",
    "from care_for_me.feature_extractor.feature_extractor import FeatureExtractor\n",
    "from care_for_me.label_generator.label_generator import LabelGenerator\n",
    "from care_for_me.feature_selector.feature_selector import FeatureSelector\n",
    "from care_for_me.classification.estimator import Estimator\n",
    "from care_for_me.pipeline.pipeline import Pipeline\n",
    "\n",
    "\n",
    "label_gen = generate_labels_3_class\n",
    "signal_acq = SignalAcquisition(signal_types=signal_types, source_folder=SOURCE_FOLDER)\n",
    "signal_preprocessor = SignalPreprocessor(skip=True, resample_rate=250)\n",
    "feature_extractor = FeatureExtractor(feature_extraction_methods=feature_extraction_methods, calculate_mean=True)\n",
    "label_generator = LabelGenerator(label_generation_method=label_gen)\n",
    "\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(criterion=\"entropy\"),\n",
    "    \"RF\": RandomForestClassifier(criterion=\"entropy\", n_estimators=100),\n",
    "    \"AB\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=9)\n",
    "}\n",
    "\n",
    "accs = {\n",
    "    \"SVM\": [],\n",
    "    \"RF\": []\n",
    "}\n",
    "\n",
    "aucs = {\n",
    "    \"SVM\": [],\n",
    "    \"RF\": []\n",
    "}\n",
    "\n",
    "true = {\n",
    "    \"SVM\": [],\n",
    "    \"RF\": []\n",
    "}\n",
    "\n",
    "preds = {\n",
    "    \"SVM\": [],\n",
    "    \"RF\": []\n",
    "}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    model = models[model_name]\n",
    "    estimator_train = Estimator(0, model, name=\"Classification: training\")\n",
    "    estimator_test = Estimator(1, model, name=\"Classification: testing\")\n",
    "    estimator_train_val_test = Estimator(2, model, name=\"Classification: train-val-test\", random_seed=18)\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "\n",
    "    pipeline.generate_nodes_from_layers(\n",
    "        [signal_acq, signal_preprocessor, feature_extractor, label_generator, estimator_train_val_test]\n",
    "    )\n",
    "\n",
    "    for i in range(5):\n",
    "        # We leave it up to the user to handle the final output of the pipeline. \n",
    "        out = pipeline.run()\n",
    "\n",
    "        # Results\n",
    "        # fitted_model = out[0]\n",
    "        y_true = out[1]\n",
    "        y_pred = out[2]\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "        true[model_name].append(y_true)\n",
    "        preds[model_name].append(y_pred)\n",
    "        accs[model_name].append(acc)\n",
    "        aucs[model_name].append(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
