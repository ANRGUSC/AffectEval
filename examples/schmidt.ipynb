{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"../affecteval\"))\n",
    "sys.path.insert(0, module_path)\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "sys.path.insert(0, module_path)\n",
    "\n",
    "import biosppy as bp\n",
    "import heartpy as hp\n",
    "import neurokit2 as nk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyhrv\n",
    "import pyhrv.time_domain as td\n",
    "import scipy\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from affecteval.signals import Features, Signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"../affecteval\"))\n",
    "sys.path.insert(0, module_path)\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "sys.path.insert(0, module_path)\n",
    "\n",
    "import wesad\n",
    "\n",
    "subject_indices = list(range(2, 12)) + list(range(13, 18))\n",
    "SUBJECTS = [str(i) for i in subject_indices]\n",
    "\n",
    "# NOTE: Change ROOT_DIR according to your own file structure. This will be the only place you will need to do this.\n",
    "ROOT_DIR = \"/Users/emilyzhou/Desktop/Research/CAREForMe/\"\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "WESAD_PATH = os.path.join(DATA_DIR, \"WESAD\")\n",
    "SOURCE_FOLDER = os.path.join(WESAD_PATH, \"formatted\")\n",
    "ANNOTATIONS_PATH = os.path.join(WESAD_PATH, \"annotations\")\n",
    "METRICS = os.path.join(DATA_DIR, \"metrics\", \"WESAD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data to be compatible with CAREforMe pipeline\n",
    "# Only needs to be run once locally \n",
    "# Status: COMPLETE, do not re-run\n",
    "\n",
    "# wesad.reformat_and_save_data(WESAD_PATH)\n",
    "\n",
    "# Rename Medi_1 and Medi_2 files to Medi1 and Medi2\n",
    "# files_to_rename = glob.glob(os.path.join(SOURCE_FOLDER, \"*/*Medi_*.csv\"))\n",
    "# for file in files_to_rename:\n",
    "#     file_name = file.split(\"_\")\n",
    "#     new_name = f\"{file_name[0]}_{file_name[1]}{file_name[2]}_{file_name[3]}\"\n",
    "#     os.rename(file, new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate WESAD labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_labels_3_class(data):\n",
    "    print(data.shape)\n",
    "    labels = []\n",
    "    for i in range(data.shape[0]):\n",
    "        phase = data[\"Phase\"].iloc[i]\n",
    "        if phase == \"Base\":     # Baseline\n",
    "            labels.append(0)\n",
    "        elif phase == \"TSST\": \n",
    "            labels.append(1)    # Stress\n",
    "        elif phase == \"Fun\":\n",
    "            labels.append(2)    # Amusement\n",
    "    labels = np.array(labels).ravel()\n",
    "    return labels, data\n",
    "\n",
    "def generate_labels_binary(data):\n",
    "    labels = []\n",
    "    for i in range(data.shape[0]):\n",
    "        phase = data[\"Phase\"].iloc[i]\n",
    "        if phase == \"Base\" or phase == \"Fun\":     # Non-stress\n",
    "            labels.append(0)\n",
    "        elif phase == \"TSST\": \n",
    "            labels.append(1)    # Stress\n",
    "    labels = np.array(labels).ravel()\n",
    "    return labels, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# Preprocessing methods\n",
    "# ECG ------------------------------\n",
    "def preprocess_ecg(data, fs):\n",
    "    return data\n",
    "\n",
    "# EDA ------------------------------\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    return butter(order, cutoff, fs=fs, btype='low', analog=False)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def preprocess_eda(data, fs):\n",
    "    return butter_lowpass_filter(data, 5, fs)\n",
    "\n",
    "# EMG ------------------------------\n",
    "def preprocess_emg(data, fs):\n",
    "    return data\n",
    "\n",
    "# RESP ------------------------------\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def preprocess_resp(data, fs):\n",
    "    return butter_bandpass_filter(data, 0.1, 0.35, fs)\n",
    "\n",
    "# TEMP ------------------------------\n",
    "def preprocess_temp(data, fs):\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE EXTRACTION TEMPLATE\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical/common feature extraction methods\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_min(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.min(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.min(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_max(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.max(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.max(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_mean(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.mean(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.mean(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_med(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.median(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.median(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_std(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.std(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.std(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_var(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.var(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.var(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_range(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.max(segment) - np.min(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.max(segment) - np.min(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_peak(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.max(segment)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.max(segment)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_slope(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        feature = np.mean(np.gradient(segment))\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.mean(np.gradient(segment))\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract power from frequency bands\n",
    "\n",
    "def bandpower(x, fs, fmin, fmax):\n",
    "    f, Pxx = scipy.signal.periodogram(x, fs=fs)\n",
    "    ind_min = np.argmax(f > fmin) - 1\n",
    "    ind_max = np.argmax(f > fmax) - 1\n",
    "    return np.trapezoid(Pxx[ind_min: ind_max], f[ind_min: ind_max])\n",
    "\n",
    "def extract_freq_power(data, fs, low, high):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = bandpower(segment, fs, low, high)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = bandpower(segment, fs, low, high)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG feature extraction methods\n",
    "from pyhrv.hrv import hrv\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_ecg_features_pyhrv(data, fs):\n",
    "    n = data.size\n",
    "    if n == 0:\n",
    "        print(\"ECG signal has length 0, returning None\")\n",
    "        return None\n",
    "    \n",
    "    hr = []\n",
    "    rmssd = []\n",
    "    sdnn = []\n",
    "    tinn = []\n",
    "    nn50 = []\n",
    "\n",
    "    start = 0\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "    stop = start + window_size\n",
    "    if stop >= n:\n",
    "        t, filtered_signal, rpeaks, _, _, _, bpm = bp.signals.ecg.ecg(signal=data, sampling_rate=fs, show=False)\n",
    "        bpm = np.mean(bpm)\n",
    "        rmssd_segment = td.rmssd(rpeaks=t[rpeaks])[\"rmssd\"]\n",
    "        sdnn_segment = td.sdnn(rpeaks=t[rpeaks])[\"sdnn\"]\n",
    "        tinn_segment = td.tinn(rpeaks=t[rpeaks])[\"tinn\"]\n",
    "        nn50_segment = td.nnXX(rpeaks=t[rpeaks], threshold=50)[\"nn50\"]\n",
    "\n",
    "        hr.append(bpm)\n",
    "        rmssd.append(rmssd_segment)\n",
    "        sdnn.append(sdnn_segment)\n",
    "        tinn.append(tinn_segment)\n",
    "        nn50.append(nn50_segment)\n",
    "    else:\n",
    "        while stop < n:\n",
    "            stop = start + window_size\n",
    "            segment = data[start:stop]\n",
    "            if len(segment) < fs*4:\n",
    "                continue\n",
    "            segment, info = nk.ecg_process(segment, sampling_rate=fs)\n",
    "            segment = segment[\"ECG_Clean\"]\n",
    "            t, filtered_signal, rpeaks, _, _, _, bpm = bp.signals.ecg.ecg(signal=segment, sampling_rate=fs, show=False)\n",
    "            try:\n",
    "                segment = data.iloc[start:stop]\n",
    "            except AttributeError:\n",
    "                segment = data[start:stop]\n",
    "            try:\n",
    "                bpm = np.mean(bpm)\n",
    "                rmssd_segment = np.mean(td.rmssd(rpeaks=t[rpeaks])[\"rmssd\"])\n",
    "                sdnn_segment = td.sdnn(rpeaks=t[rpeaks])[\"sdnn\"]\n",
    "                tinn_segment = td.tinn(rpeaks=t[rpeaks], plot=False)[\"tinn\"]\n",
    "                nn50_segment = td.nnXX(rpeaks=t[rpeaks], threshold=50)[\"nn50\"]\n",
    "            except Exception as e:\n",
    "                bpm = np.nan\n",
    "                rmssd_segment = np.nan\n",
    "                sdnn_segment = np.nan\n",
    "                tinn_segment = np.nan\n",
    "                nn50_segment = np.nan\n",
    "            hr.append(bpm)\n",
    "            rmssd.append(rmssd_segment)\n",
    "            sdnn.append(sdnn_segment)\n",
    "            tinn.append(tinn_segment)\n",
    "            nn50.append(nn50_segment)\n",
    "\n",
    "            start = stop - overlap\n",
    "    return hr, rmssd, sdnn, tinn, nn50\n",
    "    \n",
    "def extract_hr(data, fs):\n",
    "    hr, _, _, _, _ = extract_ecg_features_pyhrv(data, fs)\n",
    "    return hr\n",
    "\n",
    "def extract_rmssd(data, fs):\n",
    "    _, rmssd, _, _, _ = extract_ecg_features_pyhrv(data, fs)\n",
    "    return rmssd\n",
    "\n",
    "def extract_sdnn(data, fs):\n",
    "    _, _, sdnn, _, _ = extract_ecg_features_pyhrv(data, fs)\n",
    "    return sdnn\n",
    "\n",
    "def extract_hr_mean(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        t, filtered_signal, rpeaks, _, _, _, bpm = bp.signals.ecg.ecg(signal=data, sampling_rate=fs, show=False)\n",
    "        bpm = np.mean(bpm)\n",
    "        out.append(bpm)\n",
    "    else:\n",
    "        while stop < n:\n",
    "            stop = start + window_size\n",
    "            segment = data[start:stop]\n",
    "            if len(segment) < fs*4:\n",
    "                continue\n",
    "            segment, info = nk.ecg_process(segment, sampling_rate=fs)\n",
    "            segment = segment[\"ECG_Clean\"]\n",
    "            t, filtered_signal, rpeaks, _, _, _, bpm = bp.signals.ecg.ecg(signal=segment, sampling_rate=fs, show=False)\n",
    "            try:\n",
    "                segment = data.iloc[start:stop]\n",
    "            except AttributeError:\n",
    "                segment = data[start:stop]\n",
    "            try:\n",
    "                bpm = np.mean(bpm)\n",
    "            except Exception as e:\n",
    "                bpm = np.nan\n",
    "            out.append(bpm)\n",
    "            start = stop - overlap\n",
    "    out = [np.mean(out)]\n",
    "    return out\n",
    "\n",
    "def extract_tinn(data, fs):\n",
    "    _, _, _, tinn, _ = extract_ecg_features_pyhrv(data, fs)\n",
    "    return tinn\n",
    "\n",
    "def extract_nn50(data, fs):\n",
    "    _, _, _, _, nn50 = extract_ecg_features_pyhrv(data, fs)\n",
    "    return nn50\n",
    "\n",
    "def extract_ulf(data, fs):\n",
    "    low = 0\n",
    "    high = 0.03\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "\n",
    "def extract_lf(data, fs):\n",
    "    low = 0.03\n",
    "    high = 0.5\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "\n",
    "def extract_hf(data, fs):\n",
    "    low = 0.12\n",
    "    high = 0.488\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "\n",
    "def extract_uhf(data, fs):\n",
    "    low = 150\n",
    "    high = 250\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "\n",
    "def extract_lf_hf_ratio(data, fs):\n",
    "    lf = extract_lf(data, fs)\n",
    "    hf = extract_hf(data, fs)\n",
    "    return np.divide(lf, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA feature extraction\n",
    "\n",
    "# Minimum threshold by which to exclude SCRs (peaks) as relative to the largest amplitude in the signal (from neurokit documentation)\n",
    "MIN_AMP = 0.3 \n",
    "def extract_eda_features_nk(signal, fs):\n",
    "    signal = signal.astype(np.double)\n",
    "    signal = hp.scale_data(signal)\n",
    "    signal = scipy.ndimage.median_filter(signal, int(fs))  # Median smoothing to reject outliers\n",
    "    signals, info = nk.eda_process(signal, sampling_rate=fs)\n",
    "    phasic = signals[\"EDA_Phasic\"].to_numpy()\n",
    "    tonic = signals[\"EDA_Tonic\"].to_numpy()\n",
    "\n",
    "    peak_info = nk.eda_findpeaks(phasic, fs, amplitude_min=MIN_AMP)\n",
    "    peak_idx = peak_info[\"SCR_Peaks\"].astype(int)\n",
    "    peak_amps = peak_info[\"SCR_Height\"]\n",
    "    peaks = np.zeros(phasic.shape)\n",
    "    np.put(peaks, peak_idx, [1])\n",
    "    tonic = tonic - peaks\n",
    "\n",
    "    return tonic, peaks\n",
    "\n",
    "def extract_mean_scl(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    out = []\n",
    "\n",
    "    tonic, _ = extract_eda_features_nk(data, fs)\n",
    "\n",
    "    if tonic is None:\n",
    "        print(\"mean SCL is None\")\n",
    "        return None\n",
    "    \n",
    "    n = tonic.size\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = tonic\n",
    "        segment_mean = np.mean(segment)\n",
    "        out.append(segment_mean)\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = tonic[start:stop]\n",
    "        segment_mean = np.mean(segment)\n",
    "        out.append(segment_mean)\n",
    "        start = stop - overlap\n",
    "    mean_scl = list(out)\n",
    "    return mean_scl\n",
    "\n",
    "def extract_scr_rate(data, fs):\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    out = []\n",
    "\n",
    "    _, peaks = extract_eda_features_nk(data, fs)\n",
    "\n",
    "    if peaks is None:\n",
    "        print(\"SCR rate is None\")\n",
    "        return None\n",
    "\n",
    "    n = peaks.size\n",
    "    \n",
    "    if stop >= n:\n",
    "        segment = peaks\n",
    "        num_peaks = sum(segment)\n",
    "        out.append(num_peaks)\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = peaks[start:stop]\n",
    "        num_peaks = sum(segment)\n",
    "        out.append(num_peaks)\n",
    "        start = stop - overlap\n",
    "    scr_rate = list(out)\n",
    "    return scr_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMG feature extraction\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_emg_psd_1(data, fs):\n",
    "    low = 0\n",
    "    high = 50\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_2(data, fs):\n",
    "    low = 50\n",
    "    high = 100\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_3(data, fs):\n",
    "    low = 100\n",
    "    high = 150\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_4(data, fs):\n",
    "    low = 150\n",
    "    high = 200\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_5(data, fs):\n",
    "    low = 200\n",
    "    high = 250\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_6(data, fs):\n",
    "    low = 250\n",
    "    high = 300\n",
    "    return extract_freq_power(data, fs, low, high)\n",
    "    \n",
    "def extract_emg_psd_7(data, fs):\n",
    "    low = 300\n",
    "    high = 350\n",
    "    return extract_freq_power(data, fs, low, high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESP feature extraction\n",
    "\n",
    "WINDOW_SIZE = 60\n",
    "OVERLAP = 0.25\n",
    "\n",
    "def extract_resp(data, fs):\n",
    "    return nk.rsp_process(data, fs)\n",
    "\n",
    "def extract_resp_mean_inh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        feature = feature.value_counts().get(1, 0)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        feature = feature.value_counts().get(1, 0)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_mean_exh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        feature = feature.value_counts().get(0)\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        feature = feature.value_counts().get(0)\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_std_inh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_std_exh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_inh_exh(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        inh = feature.value_counts().get(1, 0)\n",
    "        exh = feature.value_counts().get(0)\n",
    "        feature = inh/exh\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = segment[\"RSP_Phase\"]\n",
    "        inh = feature.value_counts().get(1, 0)\n",
    "        exh = feature.value_counts().get(0)\n",
    "        feature = inh/exh\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_vol(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = np.mean(segment[\"RSP_RVT\"])\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.mean(segment[\"RSP_RVT\"])\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_rate(data, fs):\n",
    "    data = extract_resp(data, fs)\n",
    "    window_size = int(WINDOW_SIZE*fs)\n",
    "    overlap = int(OVERLAP*fs)\n",
    "\n",
    "    start = 0\n",
    "    stop = start + window_size\n",
    "    n = data.size\n",
    "    out = []\n",
    "\n",
    "    if stop >= n:\n",
    "        segment = data\n",
    "        # extract features\n",
    "        feature = np.mean(segment[\"RSP_Rate\"])\n",
    "        out.append(feature)\n",
    "\n",
    "    while stop < n:\n",
    "        stop = start + window_size\n",
    "        segment = data[start:stop]\n",
    "        # extract features\n",
    "        feature = np.mean(segment[\"RSP_Rate\"])\n",
    "        out.append(feature)\n",
    "        start = stop - overlap\n",
    "\n",
    "    out = list(out)\n",
    "    return out\n",
    "\n",
    "def extract_resp_duration(data, fs):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up parameters\n",
    "from affecteval.signal_acquisition.signal_acquisition import SignalAcquisition\n",
    "from affecteval.signal_preprocessor.signal_preprocessor import SignalPreprocessor\n",
    "from affecteval.feature_extractor.feature_extractor import FeatureExtractor\n",
    "from affecteval.label_generator.label_generator import LabelGenerator\n",
    "from affecteval.classification.estimator import Estimator\n",
    "from affecteval.pipeline.pipeline import Pipeline\n",
    "\n",
    "\n",
    "signal_types = [\n",
    "    Signals.ECG,\n",
    "    Signals.EDA,\n",
    "    Signals.EMG,\n",
    "    Signals.RESP,\n",
    "    Signals.TEMP,\n",
    "]\n",
    "feature_names = [\n",
    "    Features.ECG_MEAN, Features.ECG_MEDIAN, Features.ECG_STD, Features.ECG_VAR,\n",
    "    Features.HR, Features.HR_MEAN, Features.RMSSD, Features.RMSSD_MEAN, Features.SDNN, Features.NN50, Features.TINN,\n",
    "    Features.ULF, Features.LF, Features.HF, Features.UHF, Features.LF_NORM, Features.HF_NORM, Features.LF_HF,\n",
    "    Features.EDA_MEAN, Features.EDA_MEDIAN, Features.EDA_STD, Features.EDA_VAR, Features.EDA_SLOPE, Features.EDA_RANGE,\n",
    "    Features.MEAN_SCL, Features.SCR_RATE,\n",
    "    Features.EMG_MEAN, Features.EMG_MEDIAN, Features.EMG_STD, Features.EMG_VAR, Features.EMG_10, Features.EMG_90, Features.EMG_NUM_PEAKS, Features.EMG_PEAK_MEAN, Features.EMG_PEAK_STD, Features.EMG_PEAK_AMP,\n",
    "    Features.EMG_F_MEAN, Features.EMG_F_MED, Features.EMG_F_PEAK, Features.EMG_PSD_1, Features.EMG_PSD_2, Features.EMG_PSD_3, Features.EMG_PSD_4, Features.EMG_PSD_5, Features.EMG_PSD_6, Features.EMG_PSD_7,\n",
    "    Features.RESP_MEAN_INH, Features.RESP_MEAN_EXH, Features.RESP_STD_INH, Features.RESP_STD_EXH, Features.RESP_INH_EXH, Features.RESP_RANGE, Features.RESP_VOL, Features.RESP_RATE, Features.RESP_DURATION,\n",
    "    Features.TEMP_MEAN, Features.TEMP_STD, Features.TEMP_MIN, Features.TEMP_MAX, Features.TEMP_SLOPE, Features.TEMP_RANGE\n",
    "]\n",
    "\n",
    "preprocessing_methods = {\n",
    "    \"ECG\": preprocess_ecg,\n",
    "    \"EDA\": preprocess_eda,\n",
    "    \"EMG\": preprocess_emg,\n",
    "    \"RESP\": preprocess_resp,\n",
    "    \"TEMP\": preprocess_temp\n",
    "}\n",
    "\n",
    "feature_extraction_methods = {\n",
    "    \"ECG\": {\n",
    "        Features.ECG_MEAN: extract_mean,\n",
    "        Features.ECG_MEDIAN: extract_med,\n",
    "        Features.ECG_STD: extract_std,\n",
    "        Features.ECG_VAR: extract_var,\n",
    "        # Features.HR: extract_hr, Features.HR_MEAN: extract_hr_mean, \n",
    "        # Features.RMSSD: extract_rmssd, Features.RMSSD_MEAN: extract_rmssd, \n",
    "        # Features.SDNN: extract_sdnn, Features.NN50: extract_nn50, Features.TINN: extract_tinn,\n",
    "        # Features.ULF: extract_ulf, Features.LF: extract_lf, Features.HF: extract_hf, Features.UHF: extract_uhf, \n",
    "        # Features.LF_NORM: extract_lf, Features.HF_NORM: extract_hf, \n",
    "        # Features.LF_HF: extract_lf_hf_ratio,\n",
    "    },\n",
    "    \"EDA\": {\n",
    "        Features.EDA_MEAN: extract_mean,\n",
    "        Features.EDA_MEDIAN: extract_med,\n",
    "        Features.EDA_STD: extract_std,\n",
    "        Features.EDA_VAR: extract_var,\n",
    "        # Features.EDA_SLOPE: extract_slope,\n",
    "        Features.EDA_RANGE: extract_range,\n",
    "        # Features.MEAN_SCL: extract_mean_scl, Features.SCR_RATE: extract_scr_rate,\n",
    "    },\n",
    "    \"EMG\": {\n",
    "        Features.EMG_MEAN: extract_mean,\n",
    "        Features.EMG_MEDIAN: extract_med,\n",
    "        Features.EMG_STD: extract_std,\n",
    "        Features.EMG_VAR: extract_var,\n",
    "\n",
    "    },\n",
    "    \"RESP\": {\n",
    "\n",
    "    },\n",
    "    \"TEMP\": {\n",
    "        Features.TEMP_MEAN: extract_mean,\n",
    "        Features.TEMP_STD: extract_std,\n",
    "        Features.TEMP_MIN: extract_min,\n",
    "        Features.TEMP_MAX: extract_max,\n",
    "        Features.TEMP_SLOPE: extract_slope\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running node Signal Acquisition...\n",
      "- Elapsed time: 0.0 s\n",
      "Running node Signal Preprocessor...\n",
      "- Elapsed time: 30.721 s\n",
      "Running node Feature Extractor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Elapsed time: 0.658 s\n",
      "Running node Label Generator...\n",
      "(581, 16)\n",
      "- Elapsed time: 0.003 s\n",
      "Running node Classification: train-val-test...\n",
      "DT --------------------------------------------------\n",
      "Cross-validation acc: [0.87096774 0.8172043  0.79569892 0.77419355 0.82608696]\n",
      "Cross-validation mean acc: 0.8168302945301542\n",
      "Cross-validation std acc: 0.03249958705871656\n",
      "Cross-validation f1: [0.86522444 0.81145471 0.77259818 0.74947138 0.84819653]\n",
      "Cross-validation mean f1: 0.8093890495286399\n",
      "Cross-validation std f1: 0.04375288042202031\n",
      "RF --------------------------------------------------\n",
      "Cross-validation acc: [0.91397849 0.90322581 0.93548387 0.84946237 0.92391304]\n",
      "Cross-validation mean acc: 0.905212716222534\n",
      "Cross-validation std acc: 0.029849399746023637\n",
      "Cross-validation f1: [0.92325269 0.90164413 0.92364643 0.872429   0.93307954]\n",
      "Cross-validation mean f1: 0.910810358922606\n",
      "Cross-validation std f1: 0.02178366790866064\n",
      "AB --------------------------------------------------\n",
      "Cross-validation acc: [0.78494624 0.74193548 0.7311828  0.77419355 0.84782609]\n",
      "Cross-validation mean acc: 0.7760168302945301\n",
      "Cross-validation std acc: 0.041015257716276794\n",
      "Cross-validation f1: [0.77388442 0.74135429 0.72384322 0.74745208 0.84170569]\n",
      "Cross-validation mean f1: 0.765647939474621\n",
      "Cross-validation std f1: 0.041283230334911186\n",
      "LDA --------------------------------------------------\n",
      "Cross-validation acc: [0.74193548 0.67741935 0.69892473 0.66666667 0.70652174]\n",
      "Cross-validation mean acc: 0.6982935951379149\n",
      "Cross-validation std acc: 0.026110195905245038\n",
      "Cross-validation f1: [0.70725242 0.63588011 0.6628509  0.63808246 0.68079465]\n",
      "Cross-validation mean f1: 0.664972108658165\n",
      "Cross-validation std f1: 0.026877036507030463\n",
      "KNN --------------------------------------------------\n",
      "Cross-validation acc: [0.77419355 0.80645161 0.69892473 0.76344086 0.79347826]\n",
      "Cross-validation mean acc: 0.7672978027115475\n",
      "Cross-validation std acc: 0.03729810039669206\n",
      "Cross-validation f1: [0.75912906 0.79113288 0.6710148  0.73737008 0.76674061]\n",
      "Cross-validation mean f1: 0.745077486588672\n",
      "Cross-validation std f1: 0.04082284193418125\n",
      "- Elapsed time: 2.689 s\n"
     ]
    }
   ],
   "source": [
    "from affecteval.signal_acquisition.signal_acquisition import SignalAcquisition\n",
    "from affecteval.signal_preprocessor.signal_preprocessor import SignalPreprocessor\n",
    "from affecteval.feature_extractor.feature_extractor import FeatureExtractor\n",
    "from affecteval.label_generator.label_generator import LabelGenerator\n",
    "from affecteval.classification.estimator import Estimator\n",
    "from affecteval.pipeline.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "label_gen = generate_labels_3_class\n",
    "signal_acq = SignalAcquisition(signal_types=signal_types, source_folder=SOURCE_FOLDER)\n",
    "signal_preprocessor = SignalPreprocessor(skip=True, resample_rate=250)\n",
    "feature_extractor = FeatureExtractor(feature_extraction_methods=feature_extraction_methods, calculate_mean=False)\n",
    "label_generator = LabelGenerator(label_generation_method=label_gen)\n",
    "\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(criterion=\"entropy\"),\n",
    "    \"RF\": RandomForestClassifier(criterion=\"entropy\", n_estimators=100),\n",
    "    \"AB\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=9)\n",
    "}\n",
    "\n",
    "accs = {\n",
    "    \"DT\": [],\n",
    "    \"RF\": [],\n",
    "    \"AB\": [],\n",
    "    \"LDA\": [],\n",
    "    \"KNN\": [],\n",
    "}\n",
    "\n",
    "f1s = {\n",
    "    \"DT\": [],\n",
    "    \"RF\": [],\n",
    "    \"AB\": [],\n",
    "    \"LDA\": [],\n",
    "    \"KNN\": [],\n",
    "}\n",
    "\n",
    "true = {\n",
    "    \"DT\": [],\n",
    "    \"RF\": [],\n",
    "    \"AB\": [],\n",
    "    \"LDA\": [],\n",
    "    \"KNN\": [],\n",
    "}\n",
    "\n",
    "preds = {\n",
    "    \"DT\": [],\n",
    "    \"RF\": [],\n",
    "    \"AB\": [],\n",
    "    \"LDA\": [],\n",
    "    \"KNN\": [],\n",
    "}\n",
    "\n",
    "estimator_train_val_test = Estimator(2, models, name=\"Classification: train-val-test\", random_seed=36)\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "pipeline.generate_nodes_from_layers(\n",
    "    [signal_acq, signal_preprocessor, feature_extractor, label_generator, estimator_train_val_test]\n",
    ")\n",
    "\n",
    "# We leave it up to the user to handle the final output of the pipeline. \n",
    "out = pipeline.run()\n",
    "\n",
    "# Results\n",
    "# fitted_models = out[0]\n",
    "y_true = out[1]\n",
    "y_preds = out[2]\n",
    "\n",
    "\n",
    "for model_name in models.keys():\n",
    "    model = models[model_name]\n",
    "    acc = accuracy_score(y_true, y_preds[model_name])\n",
    "    f1 = f1_score(y_true, y_preds[model_name], average='micro')\n",
    "\n",
    "    true[model_name].append(y_true)\n",
    "    preds[model_name].append(y_preds[model_name])\n",
    "    accs[model_name].append(acc)\n",
    "    f1s[model_name].append(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running node Signal Acquisition...\n",
      "- Elapsed time: 0.0 s\n",
      "Running node Signal Preprocessor...\n",
      "- Elapsed time: 30.564 s\n",
      "Running node Feature Extractor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 23.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Elapsed time: 0.647 s\n",
      "Running node Label Generator...\n",
      "- Elapsed time: 0.003 s\n",
      "Running node Classification: train-val-test...\n",
      "DT --------------------------------------------------\n",
      "Cross-validation acc: [0.96774194 0.93548387 0.93548387 0.96774194 0.9673913 ]\n",
      "Cross-validation mean acc: 0.9547685834502104\n",
      "Cross-validation std acc: 0.01574642232318585\n",
      "Cross-validation f1: [0.967584   0.93548387 0.9131041  0.92438965 0.95652174]\n",
      "Cross-validation mean f1: 0.9394166713903971\n",
      "Cross-validation std f1: 0.020097819019838786\n",
      "RF --------------------------------------------------\n",
      "Cross-validation acc: [0.96774194 0.96774194 0.94623656 0.96774194 0.94565217]\n",
      "Cross-validation mean acc: 0.9590229079008882\n",
      "Cross-validation std acc: 0.010680183219333988\n",
      "Cross-validation f1: [0.967584   0.96723154 0.92151709 0.9459926  0.95689575]\n",
      "Cross-validation mean f1: 0.9518441955079183\n",
      "Cross-validation std f1: 0.017111425498110247\n",
      "AB --------------------------------------------------\n",
      "Cross-validation acc: [0.93548387 0.93548387 0.93548387 0.93548387 0.91304348]\n",
      "Cross-validation mean acc: 0.9309957924263674\n",
      "Cross-validation std acc: 0.008976157082748949\n",
      "Cross-validation f1: [0.9340719  0.93548387 0.9340719  0.93548387 0.91442301]\n",
      "Cross-validation mean f1: 0.930706911232513\n",
      "Cross-validation std f1: 0.008166399839313176\n",
      "LDA --------------------------------------------------\n",
      "Cross-validation acc: [0.89247312 0.8172043  0.8172043  0.84946237 0.80434783]\n",
      "Cross-validation mean acc: 0.8361383824216924\n",
      "Cross-validation std acc: 0.03187089373275059\n",
      "Cross-validation f1: [0.89011984 0.81201787 0.79922723 0.84452047 0.78300395]\n",
      "Cross-validation mean f1: 0.8257778728557336\n",
      "Cross-validation std f1: 0.03798698690450717\n",
      "KNN --------------------------------------------------\n",
      "Cross-validation acc: [0.89247312 0.92473118 0.77419355 0.88172043 0.89130435]\n",
      "Cross-validation mean acc: 0.8728845254791959\n",
      "Cross-validation std acc: 0.05143745885651619\n",
      "Cross-validation f1: [0.88703352 0.92354025 0.75670418 0.87860133 0.89223936]\n",
      "Cross-validation mean f1: 0.8676237294728617\n",
      "Cross-validation std f1: 0.05750301226294667\n",
      "- Elapsed time: 2.412 s\n"
     ]
    }
   ],
   "source": [
    "from affecteval.signal_acquisition.signal_acquisition import SignalAcquisition\n",
    "from affecteval.signal_preprocessor.signal_preprocessor import SignalPreprocessor\n",
    "from affecteval.feature_extractor.feature_extractor import FeatureExtractor\n",
    "from affecteval.label_generator.label_generator import LabelGenerator\n",
    "from affecteval.feature_selector.feature_selector import FeatureSelector\n",
    "from affecteval.classification.estimator import Estimator\n",
    "from affecteval.pipeline.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "label_gen = generate_labels_binary\n",
    "signal_acq = SignalAcquisition(signal_types=signal_types, source_folder=SOURCE_FOLDER)\n",
    "signal_preprocessor = SignalPreprocessor(skip=True, resample_rate=250)\n",
    "feature_extractor = FeatureExtractor(feature_extraction_methods=feature_extraction_methods, calculate_mean=False)\n",
    "label_generator = LabelGenerator(label_generation_method=label_gen)\n",
    "\n",
    "models = {\n",
    "    \"DT\": DecisionTreeClassifier(criterion=\"entropy\"),\n",
    "    \"RF\": RandomForestClassifier(criterion=\"entropy\", n_estimators=100),\n",
    "    \"AB\": AdaBoostClassifier(n_estimators=100),\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=9)\n",
    "}\n",
    "\n",
    "accs = {\n",
    "    \"DT\": [],\n",
    "    \"RF\": [],\n",
    "    \"AB\": [],\n",
    "    \"LDA\": [],\n",
    "    \"KNN\": [],\n",
    "}\n",
    "\n",
    "f1s = {\n",
    "    \"DT\": [],\n",
    "    \"RF\": [],\n",
    "    \"AB\": [],\n",
    "    \"LDA\": [],\n",
    "    \"KNN\": [],\n",
    "}\n",
    "\n",
    "true = {\n",
    "    \"DT\": [],\n",
    "    \"RF\": [],\n",
    "    \"AB\": [],\n",
    "    \"LDA\": [],\n",
    "    \"KNN\": [],\n",
    "}\n",
    "\n",
    "preds = {\n",
    "    \"DT\": [],\n",
    "    \"RF\": [],\n",
    "    \"AB\": [],\n",
    "    \"LDA\": [],\n",
    "    \"KNN\": [],\n",
    "}\n",
    "\n",
    "estimator_train_val_test = Estimator(2, models, name=\"Classification: train-val-test\", random_seed=36)\n",
    "\n",
    "pipeline = Pipeline()\n",
    "\n",
    "pipeline.generate_nodes_from_layers(\n",
    "    [signal_acq, signal_preprocessor, feature_extractor, label_generator, estimator_train_val_test]\n",
    ")\n",
    "\n",
    "# We leave it up to the user to handle the final output of the pipeline. \n",
    "out = pipeline.run()\n",
    "\n",
    "# Results\n",
    "# fitted_models = out[0]\n",
    "y_true = out[1]\n",
    "y_preds = out[2]\n",
    "\n",
    "\n",
    "for model_name in models.keys():\n",
    "    model = models[model_name]\n",
    "    acc = accuracy_score(y_true, y_preds[model_name])\n",
    "    f1 = f1_score(y_true, y_preds[model_name], average='micro')\n",
    "\n",
    "    true[model_name].append(y_true)\n",
    "    preds[model_name].append(y_preds[model_name])\n",
    "    accs[model_name].append(acc)\n",
    "    f1s[model_name].append(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
